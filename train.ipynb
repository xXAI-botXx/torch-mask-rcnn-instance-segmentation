{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train**\n",
    "# Mask RCNN\n",
    "Instance Segmentation with torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import os\n",
    "import cv2  # Use OpenCV instead of Pillow\n",
    "import numpy as np\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import MaskRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
    "        self.masks = list(sorted(os.listdir(os.path.join(root, \"masks\"))))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root, \"masks\", self.masks[idx])\n",
    "\n",
    "        # Use OpenCV to load the image\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Convert the mask to a tensor\n",
    "        mask = torch.as_tensor(mask, dtype=torch.uint8)\n",
    "        obj_ids = torch.unique(mask)[1:]  # remove background class\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "\n",
    "        # Create bounding boxes\n",
    "        boxes = []\n",
    "        for i in range(len(obj_ids)):\n",
    "            pos = torch.where(masks[i])\n",
    "            xmin = torch.min(pos[1])\n",
    "            xmax = torch.max(pos[1])\n",
    "            ymin = torch.min(pos[0])\n",
    "            ymax = torch.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "\n",
    "        labels = torch.ones((len(obj_ids),), dtype=torch.int64)  # all instances are \"class 1\"\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Mask RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MaskRCNN model\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = torchvision.models.detection.MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model():\n",
    "    # Load dataset\n",
    "    dataset = CustomDataset(root='path/to/dataset', transforms=get_transform(train=True))\n",
    "    dataset_test = CustomDataset(root='path/to/dataset', transforms=get_transform(train=False))\n",
    "\n",
    "    data_loader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=4)\n",
    "    data_loader_test = DataLoader(dataset_test, batch_size=2, shuffle=False, num_workers=4)\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # Create model\n",
    "    model = get_model_instance_segmentation(num_classes=2)  # Background + 1 object class\n",
    "    model.to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        i = 0\n",
    "        for images, targets in data_loader:\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Epoch [{epoch}/{num_epochs}], Step [{i}/{len(data_loader)}], Loss: {losses.item()}\")\n",
    "            i += 1\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # Evaluate after each epoch\n",
    "        # evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
