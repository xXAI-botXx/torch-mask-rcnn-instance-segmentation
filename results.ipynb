{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Compare results and create visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path to the pickle result files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "PATH = \"D:/Informatik/Projekte/torch-mask-rcnn-instance-segmentation/output/evaluations\"\n",
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading all results\n",
    "(only from one dataset?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "results = dict()\n",
    "for cur_file in os.listdir(PATH):\n",
    "    cur_path = os.path.join(PATH, cur_file)\n",
    "    cur_name = \".\".join(cur_file.split(\".\")[:-1])\n",
    "\n",
    "    # get the result\n",
    "    if cur_path.endswith(\".pkl\"):\n",
    "        with open(cur_path, \"rb\") as file:  \n",
    "            loaded_dict = pickle.load(file)\n",
    "        results[cur_name] = dict()\n",
    "        for key, value in loaded_dict.items()\n",
    "            results[cur_name][key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Significants of change "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "normality_results = {}\n",
    "for name, data in results.items():\n",
    "    iou_values = data.get(\"intersection over union\")\n",
    "\n",
    "    if iou_values:\n",
    "        shapiro_stat, shapiro_p = stats.shapiro(iou_values)\n",
    "        normality_results[name] = (shapiro_stat, shapiro_p)\n",
    "        if shapiro_p > 0.05:\n",
    "            print(f\"{name}: IOU-values are normally distributed (p-Wert = {shapiro_p:.3f})\")\n",
    "        else:\n",
    "            print(f\"{name}: IOU-values are NOT normally distributed (p-Wert = {shapiro_p:.3f})\")\n",
    "\n",
    "all_normal = all(p > 0.05 for _, p in normality_results.values())\n",
    "if all_normal:\n",
    "    print(\"\\n\\n    -> All results are normally distributed, t test will be applied.\")\n",
    "else:\n",
    "    print(\"\\n\\n    -> NOT All results are normally distributed, Wilcoxon test will be applied.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the test beginn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "keys = list(results.keys())\n",
    "num_results = len(keys)\n",
    "p_values_matrix = np.ones((num_results, num_results))  # Initialisiere mit 1 (Diagonale wird spï¿½ter 0)\n",
    "\n",
    "# pairwaise t test\n",
    "for i in range(num_results):\n",
    "    for j in range(i + 1, num_results):\n",
    "        iou_1 = results[keys[i]][\"intersection over union\"]\n",
    "        iou_2 = results[keys[j]][\"intersection over union\"]\n",
    "        \n",
    "        # making a t test o wilcoxon test\n",
    "        if all_normal:\n",
    "            _, p_value = stats.ttest_rel(iou_1, iou_2)\n",
    "        else:\n",
    "            _, p_value = stats.wilcoxon(iou_1, iou_2)\n",
    "\n",
    "        p_values_matrix[i, j] = p_value\n",
    "\n",
    "# plotting of p values of all paris\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(p_values_matrix, dtype=bool)) \n",
    "sns.heatmap(p_values_matrix, mask=mask, annot=True, fmt=\".3f\", cmap=\"coolwarm\", \n",
    "            xticklabels=keys, yticklabels=keys, cbar_kws={\"label\": \"p-Wert\"})\n",
    "\n",
    "plt.title(\"P-Values test of IOU significants\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a detailed explanation for interpreting the results from the half heatmap plot of p-values:\n",
    "\n",
    "1. **Understanding p-values in the Context of Statistical Significance**:\n",
    "   - Each cell in the heatmap represents the p-value from a pairwise statistical test comparing the Intersection over Union (IOU) results of two experiments.\n",
    "   - A **p-value** indicates the probability that the observed difference between two sets of IOU results is due to random chance. Lower p-values suggest a significant difference, while higher p-values suggest that the difference may not be meaningful.\n",
    "\n",
    "2. **Heatmap Color Coding**:\n",
    "   - **Dark Colors (Low p-values)**: These cells represent pairs of experiments where the IOU results are significantly different. For example, if a cell has a p-value < 0.05, it means that there is less than a 5% chance that the observed difference is random. This suggests that the experimental modifications in those pairs likely lead to a real change in IOU performance.\n",
    "   - **Light Colors (High p-values)**: Cells with higher p-values (e.g., > 0.05) indicate pairs of experiments where the difference in IOU is not statistically significant. In other words, the observed difference could likely be due to random variation, and there is not enough evidence to conclude a true performance difference.\n",
    "\n",
    "3. **Diagonal and Masked Elements**:\n",
    "   - The **diagonal cells** (where each experiment is compared to itself) are masked because they naturally have a p-value of 1.0 (no difference exists when comparing a result to itself).\n",
    "   - The **upper half** of the matrix is masked to simplify the plot, as the p-values are symmetrical; each pairwise comparison only needs to be shown once.\n",
    "\n",
    "4. **Choosing Significance Thresholds**:\n",
    "   - Typically, a **threshold of 0.05** is used to denote significance (darker colors in cells below this threshold), but some researchers may apply more stringent thresholds (e.g., 0.01 or 0.001) depending on their confidence requirements.\n",
    "   - If a significant number of cells show p-values below 0.05, it suggests that many experimental adjustments may genuinely affect IOU performance. Conversely, if most p-values are above 0.05, it may indicate that the experimental variations do not lead to meaningful differences in IOU performance.\n",
    "\n",
    "5. **Further Considerations and Practical Implications**:\n",
    "   - A **cluster of dark cells** for certain experiments suggests that those specific experiments may have systematically different IOU results compared to others. This can be valuable in identifying which experimental adjustments are particularly impactful.\n",
    "   - The presence of high p-values (light cells) between multiple experiments implies that those experimental variations produce similar IOU results, indicating that changing those factors may not significantly impact model performance.\n",
    "   - **Interpret the direction and magnitude** of significant differences separately from the p-values, as the heatmap itself only tells us whether the difference is statistically significant, not whether it improves or worsens IOU.\n",
    "\n",
    "By using this heatmap interpretation, you can effectively determine which experiments lead to meaningful changes in performance, guiding future adjustments or fine-tuning based on significant outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate mean IOU for each experiment\n",
    "mean_results = {name: np.mean(data[\"intersection over union\"]) for name, data in results.items()}\n",
    "\n",
    "# Plot the mean results in a bar chart using subplots\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(mean_results.keys(), mean_results.values(), color=\"skyblue\")\n",
    "ax.set_xlabel(\"Experiment\")\n",
    "ax.set_ylabel(\"Mean IOU\")\n",
    "ax.set_title(\"Mean IOU Results by Experiment\")\n",
    "ax.set_xticklabels(mean_results.keys(), rotation=45, ha=\"right\")\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... more visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
